{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "350382a1",
   "metadata": {},
   "source": [
    "Welcome to Week 6 of the [Noisebridge Python Class](https://github.com/audiodude/PythonClass)!\n",
    "\n",
    "In this lesson, we will explore doing data analysis using the popular [**Pandas**](https://pandas.pydata.org/) library.\n",
    "\n",
    "You will learn:\n",
    "\n",
    "* Loading a CSV file in Pandas into a **Dataframe**.\n",
    "* Inspecting the data, including getting summary statistics.\n",
    "* Filtering the data using **Boolean Masks**.\n",
    "* Assigning new derivative columns to the Dataframe\n",
    "* Using aggregate functions\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c42b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afbc5a6",
   "metadata": {},
   "source": [
    "First we must import the pandas library. It's common practice to import pandas `as pd`. If you remember all the way back to week 1, this syntax allows us to refer to pandas using the shortened name `pd`. This syntax is also useful if you have multiple libraries whose names would otherwise conflict."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ffedc9",
   "metadata": {},
   "source": [
    "Next, we read a CSV file into a Pandas **Dataframe**. A Dataframe is like a sheet in a spreadsheet, or a table in an SQL database. It is two dimensional, with a row for each data item and a column for each piece of data relating to that item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc004e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('links.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c797459",
   "metadata": {},
   "source": [
    "We will be using a CSV that contains recent (July 2023) data on links submitted to the [Hacker News](https://news.ycombinator.com/) link aggregation service.\n",
    "\n",
    "The CSV contains a header row with all of the column names. This is automatically used as the **index** of the columns in the Dataframe, which will provide labels for them.\n",
    "\n",
    "We can get an idea of how many rows there are in the table, how many columns there are, how populated or sparse they are (the number of rows that contain non-null data), and the datatypes associated with each column. Pandas is flexible enough to automatically assign a datatype to a column based on the data that it finds there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a33fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6630c3d4",
   "metadata": {},
   "source": [
    "We can also get the number of rows and columns of the Dataframe with the `shape` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cb172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91659e61",
   "metadata": {},
   "source": [
    "Pandas data frames act in some ways like 2D arrays, or list of lists. Imagine you had the following Python list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1567df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef00d4a7",
   "metadata": {},
   "source": [
    "You could accesss the individual items in the `data` 2D array by specifying a row index and a column index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d564012",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0455bf8",
   "metadata": {},
   "source": [
    "In a similar way, we can access a specific row and column in the Dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5eb1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[5, 7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab5036e",
   "metadata": {},
   "source": [
    "The `iloc` method refers to data by its \"coordinates\" in the Dataframe. We can also use the `loc` method to refer to data directly by its column name, which is usually more convenient: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a4f899",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[5, 'url']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7974a4b2",
   "metadata": {},
   "source": [
    "We can use slice notation to select a range of rows, with a specific column, and use the `head()` method to see the first few rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c871c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "five_through_ten_url = df.loc[5:10, 'url']\n",
    "five_through_ten_url.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a074486",
   "metadata": {},
   "source": [
    "Note that Pandas slices *include* the row at the trailing index, unlike Python slices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c60222",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits = ['apple', 'banana', 'orange', 'pear']\n",
    "fruits[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cffac2",
   "metadata": {},
   "source": [
    "We can pass in a list of column names to select as well, and use `:` for all rows (similar to the Python code `fruits[:]` which selects all elements of a list and serves to make a copy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52018f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_fruits = fruits[:]\n",
    "my_fruits.append('cherry')\n",
    "print(fruits)\n",
    "print(my_fruits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e902f688",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rows_url_title = df.loc[:, ['url', 'title']]\n",
    "all_rows_url_title.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec17048a",
   "metadata": {},
   "source": [
    "Because we will often be selecting entire columns, Pandas provides a shortcut notation for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a248c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = df['score']\n",
    "all_scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455a4b83",
   "metadata": {},
   "source": [
    "Note that this returned a Pandas **Series** object, which is a separate data container that contains only 1 column. We can calculate various basic statistics on the series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc05d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a13363f",
   "metadata": {},
   "source": [
    "We can also use methods directly on the series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddc9f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b17bcb",
   "metadata": {},
   "source": [
    "In Pandas, `NULL` values (Python `None`) are referred to as \"NA\" in Pandas. Due to quirks in Python and NumPy (which Pandas is based on), the presence of an `NA` in an integer column automatically causes the column to be converted to float (see the decimal points) and `NaN` (Not a Number) used as the `NA` value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4fe389",
   "metadata": {},
   "source": [
    "Now let's look at a few more operations on Dataframes, using a new tiny Dataframe with fruit prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac42011",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits_df = pd.DataFrame({'name': ['apple', 'banana', 'orange'], 'price': [1.29, .89, 2.29]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b26005",
   "metadata": {},
   "source": [
    "We can add 10 cents to each price with one operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cccc7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fruit price goes up by 10 cents\n",
    "fruits_df['price'] += .1\n",
    "fruits_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1da0c03",
   "metadata": {},
   "source": [
    "Note that this is not valid Python syntax, in general. You can't generally add a scalar to a list in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2958dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [10, 20, 30, 40]\n",
    "numbers + 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff66f3e",
   "metadata": {},
   "source": [
    "Pandas \"overloads\" the addition operator in its Dataframe class to allow for special operations like this. All of the operations you'd expect, like `+`, `-`, `/`, `*`, `%` and of course the shortcuts like `+=` and `*=`, work for Pandas Dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27068bb2",
   "metadata": {},
   "source": [
    "We can also assign to individual values, or entire (potentially new) columns in our Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353de14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00866c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits_df.loc[1, 'price'] = 0.69\n",
    "# We must contruct a new Dataframe and concatente them together.\n",
    "# Note that the .concat(a) function returns a new Dataframe, it does not modify\n",
    "# the original.\n",
    "fruits_df = pd.concat([fruits_df, pd.DataFrame({'name': ['grape'], 'price': [0.1]})])\n",
    "fruits_df['on_sale'] = [False, True, False, False]\n",
    "fruits_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7fca14",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5561dd8b",
   "metadata": {},
   "source": [
    "We can filter rows in our Dataframe using **Boolean Masks**. A Boolean Mask is a Dataframe or Series that contains only boolean values. It is not a separate data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fffdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a50c45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = fruits_df['price'] > 2\n",
    "mask.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87c5f21",
   "metadata": {},
   "source": [
    "The mask contains one column, and the values of every row are either `True` or `False`. When we index the `fruits_df` Dataframe using the mask, it only returns the corresponding rows for which the mask is `True`. So in this example, it will skip rows 0 and 1, where the mask is `False` and return only row 3. Note that all corresponding columns for the row are returned by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee030b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits_over_2 = fruits_df[mask]\n",
    "fruits_over_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc671fcb",
   "metadata": {},
   "source": [
    "What if we we want to combine conditions, like we do with normal boolean values? What if we want all of the fruits that have a price over 2 and doesn't start with 'a'? First, we have to use the special syntax `.str.startswith('a')` to use the `str` method `startswith`. This is because Pandas can't overload any operator to indicate the startswith method, so this syntax specifies \"Apply the `str` method `startswith` to every row of the Series and create a new Series with the corresponding boolean value\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd8134c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'apple'.startswith('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5747361",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = fruits_df['price'] > 2\n",
    "starts_with_a_mask = fruits_df['name'].str.startswith('a')\n",
    "print(mask.head())\n",
    "print(starts_with_a_mask.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda0ba78",
   "metadata": {},
   "source": [
    "Now we can use [bitwise operators](https://wiki.python.org/moin/BitwiseOperators) to emulate Python's boolean operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948e0895",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fruits_df[mask & ~starts_with_a_mask].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b101b41c",
   "metadata": {},
   "source": [
    "Here is a mapping of bitwise operators and their Python equivalent, when dealing with Boolean Masks:\n",
    "\n",
    "| Python | Pandas Boolean Mask |\n",
    "| ------ | ------------------- |\n",
    "| and    | & |\n",
    "| or     | \\| |\n",
    "| not    | ~ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b36e677",
   "metadata": {},
   "source": [
    "First, Pandas computed a final boolean mask by performing all the operations on the boolean masks we provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51150f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(mask & ~starts_with_a_mask).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cd94f4",
   "metadata": {},
   "source": [
    "Then that boolean mask was applied to the fruits Dataframe as we've seen before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41edfe6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6a3824",
   "metadata": {},
   "source": [
    "Now that we've learned some basics, let's try to answer some questions about our dataset. How many links have a score over 100?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ddedfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['score'] > 100].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b3b5b9",
   "metadata": {},
   "source": [
    "What about the number of links with titles that start with 'A'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29556bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['title'].str.startswith('A', na=False)].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351d5039",
   "metadata": {},
   "source": [
    "Can we combine these masks to find all rows with a score over 100 and that start with 'A'? (Note, we use `na=False` to instruct Pandas that if it finds an `NA` value in the Series, it should replace it with `False` instead of an `NA` in the output. If there was an `NA` in our boolean mask, it wouldn't operate properly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5586318",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_mask = df['title'].str.startswith('A', na=False)\n",
    "score_mask = df['score'] > 100\n",
    "\n",
    "a_and_over_100 = df[a_mask & score_mask]\n",
    "print(a_and_over_100.shape[0])\n",
    "a_and_over_100.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad88a88",
   "metadata": {},
   "source": [
    "We can use the `sample()` method to get a random sample of some of our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcb2737",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time'].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df9201c",
   "metadata": {},
   "source": [
    "These `time` values are stored as [UNIX timestamps](https://en.wikipedia.org/wiki/Unix_time), the number of integer seconds since January 1, 1970 at midnight in the UTC timezone. We can convert them to Python `datetime` objects and create a human readable string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aab84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "t = 1688889269\n",
    "# Convert a UNIX Timestamp to a Python datetime object\n",
    "dt = datetime.datetime.fromtimestamp(t)\n",
    "# Format the datetime as human readable\n",
    "dt.strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3ffa14",
   "metadata": {},
   "source": [
    "What if we wanted to calculate some value for all links posted in a given day, month or year? It would be useful to have this information as a separate column on our Dataframe. We can do that by first converting the timestamp using the Pandas `to_datetime` method, and then creating new columns from each of the components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4321a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary Series that stores each timestamp as a datetime\n",
    "df_dt = pd.to_datetime(df['time'], unit='s')\n",
    "print(df_dt.head())\n",
    "\n",
    "# Create new columns ('year', 'month' and 'day') for the components\n",
    "# of the datetime in the df_dt Series.\n",
    "df['year'] = df_dt.apply(lambda dt: dt.year)\n",
    "df['month'] = df_dt.apply(lambda dt: dt.month)\n",
    "df['day'] = df_dt.apply(lambda dt: dt.day)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f35e3b0",
   "metadata": {},
   "source": [
    "The `apply()` method runs the given function for each row in a Series or Dataframe and returns a Series or Dataframe with the same shape, where each cell has the result of the operation. So for example:\n",
    "\n",
    "| df_dt value | dt.year | dt.month | dt.day |\n",
    "|-|-|-|-|\n",
    "|datetime(2023, 7, 9)|2023|7|9|\n",
    "|datetime(2023, 7, 9)|2023|7|9|\n",
    "|datetime(2023, 7, 5)|2023|7|5|\n",
    "\n",
    "The `lambda` keyword lets us define ultra simple, one line anonymous functions. The code:\n",
    "\n",
    "```\n",
    "df_dt.apply(lambda dt: dt.year)\n",
    "```\n",
    "\n",
    "Is equivalent to:\n",
    "\n",
    "```\n",
    "def get_year(dt):\n",
    "  return dt.year\n",
    "  \n",
    "df_dt.apply(get_year)\n",
    "```\n",
    "\n",
    "(Special note: if you use the second syntax, there are no parentheses after get_year when we pass it to the `apply()` method. That's because we don't want to call get_year and return the result to `apply`, but rather we want to pass the entire function as an argument to `apply`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345f635a",
   "metadata": {},
   "source": [
    "We can see that our new columns have been added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36776a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52209607",
   "metadata": {},
   "source": [
    "Now let's try to figure out the mean scores for each day in our dataset. This is a simple one-liner where we use the `groupby()` method to segregate the table based on the value of one column, then provide a function to apply to all of the values in each group, keeping them grouped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914226e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['score', 'day']].groupby('day').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f15925",
   "metadata": {},
   "source": [
    "While it seems odd that the scores decrease day after day, it does make some sense. Links that have been posted earlier in the week have had more time to accumulate score. Let's double check the max score for items on day 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec47476",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['day'] == 9]['score'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5db2501",
   "metadata": {},
   "source": [
    "That's it for this lesson!\n",
    "\n",
    "Hopefully you've learned the basics of working with CSV data in a Pandas dataframe. Data analysts like using Pandas because it is easy to load and work with the data, and many questions about the data can be answered in a single Python line. Additionally, many use Pandas right inside a Jupyter notebook like this one because it allows them to easily run single lines of code without reloading all of the data by running an entire Python script each time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
